{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc23a4b0f46ff9e",
   "metadata": {},
   "source": "# 构造双半月分类数据集，并使用KNN和MLP进行分类"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons\n",
    "from plotly import express as px\n",
    "import os\n",
    "\n",
    "from tensorflow_estimator.python.estimator.keras_lib import model_to_estimator\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "X, y = make_moons(n_samples=411, noise=0.3)\n",
    "moons = pd.DataFrame(pd.concat([pd.DataFrame(X,columns=['x1', 'x2']), pd.DataFrame(y,columns=[\"label\"])], axis=1))\n",
    "\n",
    "fig = px.scatter(moons,\n",
    "                 x='x1',\n",
    "                 y='x2',\n",
    "                 color='label',\n",
    "                 color_continuous_scale=['blue', 'red'],\n",
    "                 title='散点图 - 不同标签用不同颜色表示')\n",
    "\n",
    "fig.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eb976ca1a7f94514",
   "metadata": {},
   "source": [
    "## 1、使用KNN进行分类"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a2bf177d73de944",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from my_ML_tool import plot_decision_boundary\n",
    "\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=20)\n",
    "KNN.fit(X,y)  # predict_centre为使用K_Means计算出来的中心，在这里相当于数据标签\n",
    "# a = pd.DataFrame([5,5]).T\n",
    "\n",
    "result = KNN.predict(X) # 转置之后才是 1行2列 的数据，或者使用KNN.predict(pd.array([5,5]))\n",
    "print(\"KNN 预测准确度：\", KNN.score(X,y))\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# 定义网格边界（稍微扩展数据范围以更好地显示边界）\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "# 创建网格点\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                     np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "# 预测网格点的类别\n",
    "Z = KNN.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# 添加决策边界背景（使用等高线图）\n",
    "fig.add_trace(go.Contour(\n",
    "    x=np.arange(x_min, x_max, 0.02),\n",
    "    y=np.arange(y_min, y_max, 0.02),\n",
    "    z=Z,\n",
    "    showscale=False,\n",
    "    opacity=0.4,\n",
    "    colorscale='Viridis'  # 可根据类别数调整颜色映射\n",
    "))\n",
    "\n",
    "# 添加原始数据点\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=X[:, 0],\n",
    "    y=X[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=y,\n",
    "        colorscale='Viridis',\n",
    "        showscale=False\n",
    "    ),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "# 更新布局\n",
    "fig.update_layout(\n",
    "    title='KNN Decision Boundary',\n",
    "    xaxis_title='Feature 1',\n",
    "    yaxis_title='Feature 2'\n",
    ")\n",
    "\n",
    "# 显示图形\n",
    "fig.show()\n",
    "\n",
    "#\n",
    "# print(result_cluster)\n",
    "\n",
    "plot_decision_boundary(KNN,X,y)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ea904f7216e4454b",
   "metadata": {},
   "source": [
    "## 2、使用MLP进行分类\n",
    "### 2.1 检查GPU是否可用"
   ]
  },
  {
   "cell_type": "code",
   "id": "b0c60dc406e689f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T17:18:36.972962Z",
     "start_time": "2025-10-30T17:18:36.947566Z"
    }
   },
   "source": [
    "import os\n",
    "# 设置环境变量，指向 Conda CUDA DLL 所在目录\n",
    "# os.environ[\"PATH\"] += os.pathsep + r\"E:\\Porject\\python\\conda_virtual_env\\ML_GPU_309\\Library\\bin\"\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPU 是否可用：\", gpus)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 是否可用： [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "id": "d7202f6d51727f5e",
   "metadata": {},
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(units=10,input_dim=2,activation=\"sigmoid\"))\n",
    "mlp.add(Dense(units=10,activation=\"sigmoid\"))\n",
    "mlp.add(Dense(units=10,activation=\"sigmoid\"))\n",
    "mlp.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "mlp.summary()\n",
    "\n",
    "mlp.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",)\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #如果要是GPU训练的话，这里要指定CUDA可视的设备编号\n",
    "with tf.device('/GPU:0'):\n",
    "    mlp.fit(X_train,y_train,epochs=3000, verbose=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "db7de5d1ac9098b4",
   "metadata": {},
   "source": "## 3、查看训练的网络的 各节点的参数\n"
  },
  {
   "cell_type": "code",
   "id": "665d6bda9efb43ac",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from my_ML_tool import plot_decision_boundary\n",
    "\n",
    "mlp.summary()\n",
    "\n",
    "print(\"第一层权重：\",mlp.layers[0].get_weights()[0])\n",
    "print(\"第一层偏置：\",mlp.layers[0].get_weights()[1])\n",
    "print(\"第二层权重：\",mlp.layers[1].get_weights()[0])\n",
    "print(\"第二层偏置：\",mlp.layers[1].get_weights()[1])\n",
    "\n",
    "y_predict = mlp.predict(X_train)\n",
    "\n",
    "print(\"准确度：\",accuracy_score(y_train,np.where(y_predict>0.5,1,0)))\n",
    "print(\"训练集损失值：\",mlp.evaluate(X_train,y_train,verbose=1))\n",
    "print(\"测试集损失值：\",mlp.evaluate(X_test,y_test,verbose=1))\n",
    "\n",
    "plt.scatter(X_train[:,0],X_train[:,1],c=y_predict)\n",
    "\n",
    "plot_decision_boundary(mlp,X_train,y_train)\n",
    "# plot_mlp_structure(mlp)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 绘制MLP可视化",
   "id": "595c4a5e1f032f6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from my_ML_tool import plot_mlp_structure\n",
    "\n"
   ],
   "id": "d30f77629a1993c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# minst 数据集，进行手写数字识别",
   "id": "996af8fd055106d0"
  },
  {
   "cell_type": "code",
   "id": "26670c3b3b2bcb93",
   "metadata": {},
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 展示部分数据",
   "id": "61b96b08a4bea5f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "imag1 = X_train[56]\n",
    "\n",
    "fig1 = plt.figure(figsize=(3,3))\n",
    "plt.imshow(imag1,cmap=\"gray\")\n",
    "plt.title(f\"标签：{y_train[0]}\")\n",
    "plt.show()\n"
   ],
   "id": "9c47d253c89f447e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 将这些二维的数据进行预处理",
   "id": "e6e345ac1902b529"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "format_X_train = X_train.reshape(-1,28*28) / 255.0\n",
    "format_X_test = X_test.reshape(-1,28*28) / 255.0\n",
    "\n",
    "from keras.utils import to_categorical  # 进行独热编码\n",
    "format_y_train = to_categorical(y_train)\n",
    "format_y_test = to_categorical(y_test)\n",
    "\n",
    "\n"
   ],
   "id": "f1a58747435c8027",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 建立模型",
   "id": "1702ca81e6b02deb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(units=392,input_dim=28*28,activation=\"sigmoid\"))\n",
    "mlp.add(Dense(units=392,activation=\"sigmoid\"))\n",
    "mlp.add(Dense(units=10,activation=\"softmax\"))\n",
    "mlp.summary()\n",
    "mlp.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ],
   "id": "9b31f44cd2bdad82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练模型",
   "id": "1fcf68fd4a52a0d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mlp.fit(format_X_train,format_y_train,epochs=10,verbose=1)",
   "id": "1bf2d48eb155da7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 卷积神经网络",
   "id": "3da5df084b99eb9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T17:22:59.534224Z",
     "start_time": "2025-10-30T17:22:59.298974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(r\"E:\\Porject\\python\\ML\\dataset_self\\cat_and_dog\\8year_before\\training_set\\training_set\",target_size=(50,50),batch_size=32,class_mode=\"binary\")\n",
    "#每张图片在输入网络前都会被缩放成 50×50 像素\n",
    "#每次从文件夹里读取 32张图片 作为一个批次（batch）输入到模型。"
   ],
   "id": "1e36146449d00bfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T17:23:00.804241Z",
     "start_time": "2025-10-30T17:23:00.726710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten,Dense\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# 卷积层\n",
    "model.add(Conv2D(32,(3,3),input_shape=(50,50,3),activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#第二个卷积层、池化层\n",
    "model.add(Conv2D(32,(3,3),activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening层\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(units=128,activation=\"relu\"))\n",
    "model.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ],
   "id": "555de7910cb8f563",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 24, 24, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 11, 11, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 3872)              0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 128)               495744    \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 506,017\n",
      "Trainable params: 506,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 196
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练模型",
   "id": "9a9a2df8adba4f54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T17:25:32.173864Z",
     "start_time": "2025-10-30T17:24:28.523778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.fit(training_set,epochs=10)"
   ],
   "id": "b38f8d4c8823cd0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "251/251 [==============================] - 7s 26ms/step - loss: 0.1397 - accuracy: 0.9455\n",
      "Epoch 2/10\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.1064 - accuracy: 0.9611\n",
      "Epoch 3/10\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.0754 - accuracy: 0.9755\n",
      "Epoch 4/10\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.0427 - accuracy: 0.9873\n",
      "Epoch 5/10\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.0315 - accuracy: 0.9928\n",
      "Epoch 6/10\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.0194 - accuracy: 0.9958\n",
      "Epoch 7/10\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.0215 - accuracy: 0.9949\n",
      "Epoch 8/10\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.0366 - accuracy: 0.9883\n",
      "Epoch 9/10\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.0515 - accuracy: 0.9814\n",
      "Epoch 10/10\n",
      "251/251 [==============================] - 7s 26ms/step - loss: 0.0256 - accuracy: 0.9934\n"
     ]
    }
   ],
   "execution_count": 198
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "model.evalate(training_set)\n"
   ],
   "id": "1f4df1b1deea21a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 预测\n",
    "### 待预测图片预处理"
   ],
   "id": "8f1c120c4dd5fce7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T17:30:52.100520Z",
     "start_time": "2025-10-30T17:30:52.093520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img_path = \"image/img_1.png\"\n",
    "\n",
    "# 加载图片，并调整到训练时的 target_size\n",
    "img = image.load_img(img_path, target_size=(50, 50))\n",
    "\n",
    "# 转成数组\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# 扩展维度，因为模型期望输入形状是 (batch_size, 50, 50, 3)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# 和训练时一样做归一化\n",
    "img_array = img_array / 255.0"
   ],
   "id": "e925244751e76ff4",
   "outputs": [],
   "execution_count": 217
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 正式预测",
   "id": "6bfbc794c294fad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T17:30:55.763792Z",
     "start_time": "2025-10-30T17:30:55.688452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(training_set.class_indices)\n",
    "\n",
    "prediction = model.predict(img_array)\n",
    "print(prediction)\n"
   ],
   "id": "8ed833e8128fa596",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[0.9981013]]\n"
     ]
    }
   ],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T16:16:26.089710Z",
     "start_time": "2025-10-30T16:16:23.960514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "logger = SummaryWriter(log_dir = \"logs\")"
   ],
   "id": "d86b5256845b0ca4",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[132], line 12\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# import torch\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# import os\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# print(\"当前工作目录:\", os.getcwd())\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# from torchvision import models\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# from torchvision import datasets, transforms\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SummaryWriter\n\u001B[0;32m     14\u001B[0m logger \u001B[38;5;241m=\u001B[39m SummaryWriter(log_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mE:\\Porject\\python\\conda_virtual_env\\ML_GPU_309\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:12\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m Version\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m tensorboard\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mwriter\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FileWriter, SummaryWriter  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorboard\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msummary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mwriter\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrecord_writer\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m RecordWriter  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Porject\\python\\conda_virtual_env\\ML_GPU_309\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:8\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtime\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m List, Optional, TYPE_CHECKING, Union\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfigure\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Figure\n",
      "File \u001B[1;32mE:\\Porject\\python\\conda_virtual_env\\ML_GPU_309\\lib\\site-packages\\torch\\__init__.py:2475\u001B[0m\n\u001B[0;32m   2471\u001B[0m     torch_module_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;18m__name__\u001B[39m, device_type])\n\u001B[0;32m   2472\u001B[0m     sys\u001B[38;5;241m.\u001B[39mmodules[torch_module_name] \u001B[38;5;241m=\u001B[39m module\n\u001B[1;32m-> 2475\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m   2476\u001B[0m     export \u001B[38;5;28;01mas\u001B[39;00m export,\n\u001B[0;32m   2477\u001B[0m     func \u001B[38;5;28;01mas\u001B[39;00m func,\n\u001B[0;32m   2478\u001B[0m     library \u001B[38;5;28;01mas\u001B[39;00m library,\n\u001B[0;32m   2479\u001B[0m     return_types \u001B[38;5;28;01mas\u001B[39;00m return_types,\n\u001B[0;32m   2480\u001B[0m )\n\u001B[0;32m   2481\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m cond \u001B[38;5;28;01mas\u001B[39;00m cond, while_loop \u001B[38;5;28;01mas\u001B[39;00m while_loop\n\u001B[0;32m   2482\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m vmap \u001B[38;5;28;01mas\u001B[39;00m vmap\n",
      "File \u001B[1;32mE:\\Porject\\python\\conda_virtual_env\\ML_GPU_309\\lib\\site-packages\\torch\\export\\__init__.py:64\u001B[0m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msymbolic_shapes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m StrictMinMaxConstraint\n\u001B[0;32m     44\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConstraint\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDim\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnflattenedModule\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     61\u001B[0m ]\n\u001B[1;32m---> 64\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdynamic_shapes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Constraint, Dim, dims, ShapesCollection\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexported_program\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExportedProgram, ModuleCallEntry, ModuleCallSignature\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgraph_signature\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExportBackwardSignature, ExportGraphSignature\n",
      "File \u001B[1;32mE:\\Porject\\python\\conda_virtual_env\\ML_GPU_309\\lib\\site-packages\\torch\\export\\dynamic_shapes.py:23\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     _get_node_type,\n\u001B[0;32m     13\u001B[0m     BUILTIN_TYPES,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     20\u001B[0m     tree_map_with_path,\n\u001B[0;32m     21\u001B[0m )\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexported_program\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExportedProgram\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msympy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Symbol\n",
      "File \u001B[1;32mE:\\Porject\\python\\conda_virtual_env\\ML_GPU_309\\lib\\site-packages\\torch\\export\\exported_program.py:26\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mcontextlib\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m contextmanager\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     13\u001B[0m     Any,\n\u001B[0;32m     14\u001B[0m     Callable,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m     Union,\n\u001B[0;32m     24\u001B[0m )\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m autograd_not_implemented\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_library\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfake_class_registry\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FakeScriptObject\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m first_call_function_nn_module_stack\n",
      "File \u001B[1;32mE:\\Porject\\python\\conda_virtual_env\\ML_GPU_309\\lib\\site-packages\\torch\\_higher_order_ops\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcond\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m cond\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mflex_attention\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      3\u001B[0m     flex_attention,\n\u001B[0;32m      4\u001B[0m     flex_attention_backward,\n\u001B[0;32m      5\u001B[0m )\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhints_wrap\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m hints_wrapper\n",
      "File \u001B[1;32mE:\\Porject\\python\\conda_virtual_env\\ML_GPU_309\\lib\\site-packages\\torch\\_higher_order_ops\\cond.py:6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_subclasses\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional_tensor\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpytree\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_C\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DispatchKey\n",
      "File \u001B[1;32mE:\\Porject\\python\\conda_virtual_env\\ML_GPU_309\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Any, Callable, ContextManager, Dict, List, Optional, Tuple, Union\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_inductor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01minductor_config\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpytree\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_C\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _functionalization_reapply_views_tls \u001B[38;5;28;01mas\u001B[39;00m _reapply_views\n",
      "File \u001B[1;32mE:\\Porject\\python\\conda_virtual_env\\ML_GPU_309\\lib\\site-packages\\torch\\_inductor\\config.py:44\u001B[0m\n\u001B[0;32m     40\u001B[0m verbose_progress \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# use fx aot graph codegen cache\u001B[39;00m\n\u001B[0;32m     43\u001B[0m fx_graph_cache \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m---> 44\u001B[0m     os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTORCHINDUCTOR_FX_GRAPH_CACHE\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mis_fbcode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     45\u001B[0m )\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# use remote fx aot graph codegen cache\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# False: Disables the cache\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# True: Enables the cache\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# None: Not set -- Off for OSS, JustKnobs based for internal\u001B[39;00m\n\u001B[0;32m     51\u001B[0m fx_graph_remote_cache: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m fx_graph_remote_cache_default()\n",
      "File \u001B[1;32mE:\\Porject\\python\\conda_virtual_env\\ML_GPU_309\\lib\\site-packages\\torch\\_inductor\\config.py:9\u001B[0m, in \u001B[0;36mis_fbcode\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mis_fbcode\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[1;32m----> 9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mversion\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgit_version\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)"
     ]
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T16:27:25.394516Z",
     "start_time": "2025-10-30T16:27:25.376516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "print(\"工作目录:\", os.getcwd())\n",
    "\n"
   ],
   "id": "5c5f72f43feba2f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "工作目录: E:\\Porject\\python\\ML\\ML_learn_test\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T16:16:14.229736Z",
     "start_time": "2025-10-30T16:16:14.188232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for n_iter in range(100):\n",
    "    logger.add_scalar(tag='Loss/train', scalar_value=np.random.random(), global_step=n_iter)\n",
    "    logger.add_scalar(tag='Loss/test', scalar_value=np.random.random(), global_step=n_iter)"
   ],
   "id": "18426f95ed18aa15",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[131], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n_iter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m):\n\u001B[1;32m----> 2\u001B[0m     \u001B[43mlogger\u001B[49m\u001B[38;5;241m.\u001B[39madd_scalar(tag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoss/train\u001B[39m\u001B[38;5;124m'\u001B[39m, scalar_value\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandom(), global_step\u001B[38;5;241m=\u001B[39mn_iter)\n\u001B[0;32m      3\u001B[0m     logger\u001B[38;5;241m.\u001B[39madd_scalar(tag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoss/test\u001B[39m\u001B[38;5;124m'\u001B[39m, scalar_value\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandom(), global_step\u001B[38;5;241m=\u001B[39mn_iter)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'logger' is not defined"
     ]
    }
   ],
   "execution_count": 131
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML_GPU_309)",
   "language": "python",
   "name": "ml_gpu_309"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
